{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_record_linkage",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCUedkqVktU_"
      },
      "source": [
        "# 1. Dataframe Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKz2lvoGXweQ"
      },
      "source": [
        "import pandas as pd\n",
        "!pip3 install recordlinkage\n",
        "import recordlinkage as rl\n",
        "from recordlinkage.index import Block\n",
        "from recordlinkage.preprocessing import clean\n",
        "from recordlinkage.preprocessing import phonetic\n",
        "\n",
        "# Regular expression operations\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT7LwqTaZCX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d866a505-1aa0-4e4d-da7d-c0c2560e902f"
      },
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUomP4zjYgDf"
      },
      "source": [
        "# parse file\n",
        "root = \"drive/My Drive/Colab Notebooks/DFG Arenson\"\n",
        "df = pd.read_excel(root + \"/current_master_1_26_21.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tatoPHMiaKo3"
      },
      "source": [
        "# current match numerations\n",
        "lm_family = 134\n",
        "lm_ind = 2466\n",
        "im_uid = 60734"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tCdQPGpcejB"
      },
      "source": [
        "# rename columns\n",
        "df = df.rename(columns = {# Personal Information\n",
        "                                       'Last.Name': 'last_name',\n",
        "                                       'First.Name': 'first_name', \n",
        "                                       # Places or Geography\n",
        "                                       'State/Province': 'state_or_province', \n",
        "                                       'County': 'county', \n",
        "                                       'Place': 'place', \n",
        "                                       'WARD': 'ward', \n",
        "                                       'STREET': 'street', \n",
        "                                       'PLACEOFBIRTH': 'place_of_birth',\n",
        "                                       'ROLL or Sheet#': 'roll_or_sheet',\n",
        "                                       # Years\n",
        "                                       'Census.Year': 'census_year', \n",
        "                                       'CalculatedBirthYear': 'calculated_birth_year', \n",
        "                                       # Personal information\n",
        "                                       'Sex': 'sex', \n",
        "                                       'Color..Race.or.Ethnicity': 'race',\n",
        "                                       'MARITAL': 'marital_status',\n",
        "                                       'PROFESSION': 'profession',\n",
        "                                       'Notable': 'notable',\n",
        "                                       'RELIGION': 'religion'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBXRHg1ectSB"
      },
      "source": [
        "# master info\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rcBom4ZfA5-"
      },
      "source": [
        "# chosen columns\n",
        "chosen_columns = ['last_name', \n",
        "                  'first_name',\n",
        "                  'state_or_province',\n",
        "                  'county',\n",
        "                  'place',\n",
        "                  'ward',\n",
        "                  'street',\n",
        "                  'place_of_birth',\n",
        "                  'roll_or_sheet',\n",
        "                  'lat',\n",
        "                  'long',\n",
        "                  'census_year',\n",
        "                  'calculated_birth_year',\n",
        "                  'sex',\n",
        "                  'race',\n",
        "                  'marital_status',\n",
        "                  'profession',\n",
        "                  'religion',\n",
        "                  'unique_id',\n",
        "                  'phonetic_name']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x668qHgkkqPy"
      },
      "source": [
        "# 2. Standardization/normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYR9PsV3lBSA"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uagDk14nkbi9"
      },
      "source": [
        "#name, phonetic\n",
        "column_to_parse = ['last_name', 'first_name']\n",
        "\n",
        "for c in column_to_parse:\n",
        "  df[c] = df.apply(lambda row: str(row[c]).lower(), axis = 1)\n",
        "\n",
        "df[\"phonetic_name\"] = phonetic(df['last_name'], 'soundex')+phonetic(df['first_name'], 'soundex')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOGdYNUZd9z8"
      },
      "source": [
        "# race\n",
        "def transform_race(row):    \n",
        "    \n",
        "    if pd.notnull(row['race']):\n",
        "        row['race'] = row['race'].lower()\n",
        "        row['race'] = row['race'].replace('\\xa0', '')\n",
        "        row['race'] = row['race'].replace('“', '')\n",
        "        row['race'] = row['race'].replace('”', '')\n",
        "    \n",
        "    race_dict = {'mulatto(blackandwhite)': 'MIXED',\n",
        "                 'm(wonancestry.com)': 'MIXED',\n",
        "                 'mulatto': 'MIXED',\n",
        "                 'mullato': 'MIXED',\n",
        "                 'm': 'MIXED',\n",
        "                 'm(winancestry.com)': 'MIXED',\n",
        "                 'black': 'BLACK',\n",
        "                 'b': 'BLACK',\n",
        "                 'blk': 'BLACK',\n",
        "                 'brown': 'BLACK',\n",
        "                 'african': 'BLACK',\n",
        "                 'dark': 'BLACK',\n",
        "                 'drk': 'BLACK',\n",
        "                 'african (black)': 'BLACK',\n",
        "                 'negro': 'BLACK',\n",
        "                 'blacj': 'BLACK', \n",
        "                 'bkj': 'BLACK', \n",
        "                 'light': 'WHITE',\n",
        "                 'white': 'WHITE',\n",
        "                 'w': 'WHITE',\n",
        "                 '[w]': 'WHITE',\n",
        "                 'white': 'WHITE',\n",
        "                 'seems to be white': 'WHITE',\n",
        "                 'white in black household': 'WHITE',\n",
        "                 'white but passing': 'WHITE',\n",
        "                 'ancestrysaysw': 'WHITE',\n",
        "                 'swarthy': 'BLACK',\n",
        "                 'd. brown': 'BLACK',\n",
        "                 'col.d': 'BLACK',\n",
        "                 'col\\'d': 'BLACK',\n",
        "                 }\n",
        "    if row['race'] in race_dict.keys():\n",
        "      return race_dict[row['race']]\n",
        "    elif pd.notnull(row['race']):\n",
        "      return 'OTHERS'\n",
        "    else:\n",
        "     return row['race']\n",
        "\n",
        "df['race'] = df.apply(lambda row: transform_race(row), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iJv3gFfeJ35",
        "outputId": "98a06a6a-cbb6-4d6b-afc5-0617ab01af32"
      },
      "source": [
        "df['race'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['WHITE', 'BLACK', 'OTHERS', 'MIXED', nan], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjHwLJZkqqKU"
      },
      "source": [
        "# locations (nameparser, fuzzy matching)\n",
        "def transform_state(row):    \n",
        "    \"\"\"\n",
        "    This function uses a dictionary\n",
        "    to covert historical or non-abbreviated states or provinces\n",
        "    into abbreviated form. \n",
        "    An important notice is that Canada West will all be converted into ON (Ontario).\n",
        "    Unknown values: PANA, ITER, MIL.\n",
        "    \"\"\"\n",
        "    state_dict = {'CanadaWest': 'ON',\n",
        "                  'Ontario': 'ON',\n",
        "                  'Canada West': 'ON',\n",
        "                  'Pennsylvania': 'PA',\n",
        "                  'Illinois': 'IL',\n",
        "                  'Wisconsin': 'WI',\n",
        "                  'District of Columbia': 'DC',\n",
        "                  'Alabama': 'AL',\n",
        "                  'Vermont': 'VT',\n",
        "                  'Michigan': 'MI',\n",
        "                  'Ohio': 'OH',\n",
        "                  'Massachussetts': 'MA',\n",
        "                  'Virginia': 'VA',\n",
        "                  'Canada West (Ontario)': 'ON',\n",
        "                  'New York': 'NY',\n",
        "                  'toledo': 'OH'}\n",
        "    \n",
        "    if row['state_or_province'] in state_dict.keys():\n",
        "        return state_dict[row['state_or_province']]\n",
        "    else:\n",
        "        return row['state_or_province']\n",
        "\n",
        "df['state_or_province'] = df.apply(lambda row: transform_state(row), axis = 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOdd9aLlqp5i"
      },
      "source": [
        "# dates\n",
        "import datetime\n",
        "def prc_year(row, year_col):\n",
        "    \"\"\"\n",
        "    Processing birth year.\n",
        "    If birth year is not a number, not in a date format, or is noncompliant,\n",
        "    it will be converted to NaN.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Helper functions\n",
        "    def is_number(num):\n",
        "        try:\n",
        "            float(num)\n",
        "            return True\n",
        "        except ValueError:\n",
        "            return False\n",
        "    if (type(row[year_col]) is datetime.datetime):\n",
        "        row[year_col] = row[year_col].strftime(\"%Y\")\n",
        "    non_compliant_values = ['-', 'F', '#VALUE!']\n",
        "    if row[year_col] in non_compliant_values or pd.isnull(row[year_col]):\n",
        "        return np.nan\n",
        "    elif is_number(row[year_col]):\n",
        "        return float(row[year_col])\n",
        "    elif re.findall('\\d{4}', row[year_col]):\n",
        "        return min([float(i) for i in re.findall('\\d{4}', row[year_col])])\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "df['calculated_birth_year'] = df.apply(lambda row: prc_year(row, 'calculated_birth_year'),\n",
        "                                       axis = 1)\n",
        "df['census_year'] = df.apply(lambda row: prc_year(row, 'census_year'),\n",
        "                             axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uLjRKamrDaF"
      },
      "source": [
        "# clean place of birth\n",
        "def transform_birthplace(row):    \n",
        "    \"\"\"\n",
        "    This function uses a dictionary\n",
        "    to covert places of birth to cleaner strings\n",
        "    \"\"\"\n",
        "    if pd.notnull(row['place_of_birth']):\n",
        "      row['place_of_birth'] = str(row['place_of_birth'])\n",
        "      row['place_of_birth'] = row['place_of_birth'].lower()\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace('\\xa0', '')\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace('“', '')\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace('”', '')\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace('(', '')\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace(')', '')\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace('[', '')\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace(']', '')\n",
        " \n",
        "      return row['place_of_birth']\n",
        "\n",
        "df['place_of_birth'] = df.apply(lambda row: transform_birthplace(row), axis = 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3MM07P6w_FL"
      },
      "source": [
        "df['place_of_birth'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEhnJSfFphNv"
      },
      "source": [
        "# fill empty columns\n",
        "columns_to_impute_with_unknown = ['state_or_province',\n",
        "                                  'county',\n",
        "                                  'place',\n",
        "                                  'ward',\n",
        "                                  'street',\n",
        "                                  'place_of_birth',\n",
        "                                  'sex',\n",
        "                                  'race',\n",
        "                                  'marital_status',\n",
        "                                  'profession',\n",
        "                                  'religion']\n",
        "\n",
        "for i in columns_to_impute_with_unknown:\n",
        "    df[i] = df[i].fillna('unknown')\n",
        "\n",
        "columns_to_impute_with_zero = ['roll_or_sheet',\n",
        "                               'lat',\n",
        "                               'long',]\n",
        "\n",
        "for i in columns_to_impute_with_zero:\n",
        "    df[i] = df[i].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqYl-saGLM3G"
      },
      "source": [
        "# dealing with the 'unknowns'\n",
        "chrs = 'abcdefghijklmnopqrstuvwxyz0123456789 '\n",
        "\n",
        "location_columns = ['county', 'place', 'place_of_birth', 'state_or_province']\n",
        "\n",
        "count = 0\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    if all([row[i] == 'unknown' for i in location_columns]):\n",
        "      continue\n",
        "    else:\n",
        "      for l in location_columns:\n",
        "        c = \"\".join(np.random.choice(list(chrs), 20))\n",
        "        row[l] = c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z0TszwdksXQ"
      },
      "source": [
        "# 3. Linkage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PPMBNc3j84w"
      },
      "source": [
        "# match all\n",
        "df1 = df[chosen_columns]\n",
        "df2 = df[chosen_columns]\n",
        "\n",
        "# block on phoenetic full name\n",
        "indexer = rl.Index()\n",
        "indexer.add(Block('phonetic_name', 'phonetic_name'))\n",
        "record_links = indexer.index(df1, df2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ83sKYkRPn2",
        "outputId": "288999de-1129-4737-ba20-8d7497ae1044"
      },
      "source": [
        "df[pd.isnull(df['Joint ID for Matched Records'])].shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50714, 86)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ueo2GPEpcts"
      },
      "source": [
        "# unmatched VS matched\n",
        "# df_withmatch = df[pd.notnull(df['Joint ID for Matched Records'])]\n",
        "# df_nomatch = df[pd.isnull(df['Joint ID for Matched Records'])]\n",
        "# chosen_columns.append(\"phonetic_name\")\n",
        "\n",
        "# df_withmatch = df_withmatch[chosen_columns]\n",
        "# df_nomatch = df_nomatch[chosen_columns]\n",
        "\n",
        "# indexer = rl.Index()\n",
        "# indexer.add(Block('phonetic_name', 'phonetic_name'))\n",
        "# record_links = indexer.index(df_withmatch, df_nomatch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrpp4CXSj7bZ",
        "outputId": "a6f17f82-3311-4189-bfbe-0813fcce58f9"
      },
      "source": [
        "comparer = rl.Compare()\n",
        "comparer.string('first_name', 'first_name', method = 'jarowinkler', threshold = 0.85, label = 'first_name')\n",
        "comparer.string('last_name', 'last_name', method = 'jarowinkler', threshold = 0.85, label = 'last_name')\n",
        "comparer.string('state_or_province', 'state_or_province', method = 'jarowinkler', threshold = 0.5, \n",
        "                label = 'state_or_province')\n",
        "comparer.string('county', 'county', method = 'jarowinkler', threshold = 0.35, label = 'county')\n",
        "comparer.string('place', 'place', method = 'jarowinkler', threshold = 0.35, label = 'place')\n",
        "comparer.string('place_of_birth', 'place_of_birth', method = 'jarowinkler', threshold = 0.6, label = 'place_of_birth')\n",
        "comparer.string('race', 'race', method = 'jarowinkler', threshold = 0.7, label = 'race')\n",
        "comparer.string('sex', 'sex', method = 'jarowinkler', threshold = 0.7, label = 'sex')\n",
        "\n",
        "comparer.numeric('calculated_birth_year', 'calculated_birth_year', \n",
        "                 method = 'gauss', \n",
        "                 offset = 1, \n",
        "                 scale = 1, \n",
        "                 label = 'calculated_birth_year')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Compare>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIkvZhHJj8ME"
      },
      "source": [
        "Output Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJRvgeQKq3nH"
      },
      "source": [
        "import sys\n",
        "sys.setrecursionlimit(1000000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIrPaUJblpTj"
      },
      "source": [
        "compare_vectors_rl = comparer.compute(record_links, df1, df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-RU3e_q6Rr3"
      },
      "source": [
        "result_rl = compare_vectors_rl[((compare_vectors_rl['first_name'] == 1.0) & \n",
        "                                (compare_vectors_rl['last_name'] == 1.0)) &\n",
        "                               ((compare_vectors_rl['state_or_province'] == 1.0) |\n",
        "                                (compare_vectors_rl['county'] == 1.0) |\n",
        "                                (compare_vectors_rl['place'] == 1.0) |\n",
        "                                (compare_vectors_rl['place_of_birth'] == 1.0)) &\n",
        "                               (compare_vectors_rl['sex'] == 1.0) &\n",
        "                               (compare_vectors_rl['race'] == 1.0) & (\n",
        "                               (compare_vectors_rl['calculated_birth_year'] > compare_vectors_rl['calculated_birth_year'].mean()\n",
        "                               || compare_vectors_rl['calculated_birth_year'] == np.nan))]\n",
        "                               reset_index()\n",
        "\n",
        "result_rl = result_rl[result_rl['level_0'] != result_rl['level_1']].reset_index()\n",
        "result_rl.drop('index', axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEfXul4Upc1U"
      },
      "source": [
        "def create_indexid(row):\n",
        "    return \"\".join(sorted([str(int(i)) for i in [row['level_0'], row['level_1']]]))\n",
        "\n",
        "result_rl['indexid'] = result_rl.apply(lambda row: create_indexid(row), axis = 1)\n",
        "result_rl = result_rl.drop_duplicates('indexid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXTCj9CfRdSb"
      },
      "source": [
        "# parse unsures into a dictionary\n",
        "already_seen_pairs = dict()\n",
        "\n",
        "for id, list_unsures in list(zip(df.uniqueid, df.unsures)):\n",
        "  already_seen_pairs[id] = set(list_unsures[1:-1].split(\", \"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb-ZkkFHpgst"
      },
      "source": [
        "df_result_rl = pd.DataFrame()\n",
        "\n",
        "for i in zip(result_rl['level_0'], result_rl['level_1']):\n",
        "  first = df.iloc[i[0]]\n",
        "  second = df.iloc[i[1]]\n",
        "  # if is an already-inputted match or if it's already been marked as unsure\n",
        "  if first[\"Joint ID for Matched Records\"] != second[\"Joint ID for Matched Records\"]\n",
        "    || first.uniqueid not in already_seen_pairs[second.uniqueid] || second.uniqueid in already_seen_pairs[first.uniqueid]:\n",
        "    df_result_rl = df_result_rl.append(first)\n",
        "    df_result_rl = df_result_rl.append(second)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmFaIuG-phbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed1f2487-d63e-4ee8-d561-a2daf8c7c3c5"
      },
      "source": [
        "df_result_rl.reset_index(inplace = True)\n",
        "df_result_rl = df_result_rl.drop('index', axis = 1)\n",
        "df_result_rl.head()\n",
        "df_result_rl.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4108, 87)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAnER6MypjSX"
      },
      "source": [
        "num_list = []\n",
        "for i in range(int(df_result_rl.shape[0]/2)):\n",
        "    num_list.append(i)\n",
        "    num_list.append(i)\n",
        "df_result_rl['dup_pair'] = pd.Series(num_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM6YkhVxplTj"
      },
      "source": [
        "col_order = ['dup_pair']\n",
        "col_order.extend(df.columns.tolist())\n",
        "df_result_rl = df_result_rl[col_order]\n",
        "output = root + \"/newmatches-01-03-21.xlsx\"\n",
        "df_result_rl.to_excel(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN-zNDY8oI1w"
      },
      "source": [
        "result_rl.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}