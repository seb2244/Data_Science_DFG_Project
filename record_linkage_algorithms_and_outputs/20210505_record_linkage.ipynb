{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_record_linkage",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCUedkqVktU_"
      },
      "source": [
        "# 1. Dataframe Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKz2lvoGXweQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e993e63-5f3d-493b-a14e-2150c6bab4e9"
      },
      "source": [
        "import pandas as pd\n",
        "!pip3 install recordlinkage\n",
        "import recordlinkage as rl\n",
        "from recordlinkage.index import Block\n",
        "from recordlinkage.preprocessing import clean\n",
        "from recordlinkage.preprocessing import phonetic\n",
        "\n",
        "# Regular expression operations\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting recordlinkage\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/26/babbca39d74824e8bc17428a8eb04951a1d63318af7d02beeb2106a1ec26/recordlinkage-0.14-py3-none-any.whl (944kB)\n",
            "\r\u001b[K     |▍                               | 10kB 8.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 12.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 7.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40kB 6.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71kB 5.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 92kB 5.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 102kB 5.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 112kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 122kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 133kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 143kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 153kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 163kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 174kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 184kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 194kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 204kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 215kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 225kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 235kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 245kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 256kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 266kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 276kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 286kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 296kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 307kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 317kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 327kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 337kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 348kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 358kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 368kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 378kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 389kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 399kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 409kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 419kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 430kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 440kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 450kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 460kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 471kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 481kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 491kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 501kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 512kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 522kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 532kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 542kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 552kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 563kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 573kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 583kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 593kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 604kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 614kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 624kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 634kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 645kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 655kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 665kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 675kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 686kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 696kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 706kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 716kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 727kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 737kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 747kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 757kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 768kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 778kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 788kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 798kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 808kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 819kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 829kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 839kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 849kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 860kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 870kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 880kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 890kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 901kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 911kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 921kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 931kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 942kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 952kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1 in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (1.0.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (1.1.5)\n",
            "Collecting jellyfish>=0.5.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/a6/4d039bc827a102f62ce7a7910713e38fdfd7c7a40aa39c72fb14938a1473/jellyfish-0.8.2-cp37-cp37m-manylinux2014_x86_64.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->recordlinkage) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->recordlinkage) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->recordlinkage) (1.15.0)\n",
            "Installing collected packages: jellyfish, recordlinkage\n",
            "Successfully installed jellyfish-0.8.2 recordlinkage-0.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT7LwqTaZCX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3663ef6b-9dd0-4cb8-b17a-341ec49b4d2e"
      },
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUomP4zjYgDf"
      },
      "source": [
        "# parse file\n",
        "root = \"drive/My Drive/Colab Notebooks\"\n",
        "df = pd.read_excel(root + \"/current_master_3_21_2021.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj4RcpbKFs7G",
        "outputId": "20244364-5cdd-4f79-8ef7-d3090a1108f6"
      },
      "source": [
        "for col in df.columns.unique():\n",
        "  print(col)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique_id\n",
            "source\n",
            "Census.Year\n",
            "State.Province\n",
            "County\n",
            "Place\n",
            "unsure_ids\n",
            "no_ids\n",
            "Household.Joint.ID\n",
            "Joint.ID.for.Matched.Records\n",
            "Last.Name\n",
            "First.Name\n",
            "CalculatedBirthYear\n",
            "Age\n",
            "Sex\n",
            "Color..Race.or.Ethnicity\n",
            "lat\n",
            "long\n",
            "address\n",
            "MARITAL\n",
            "WARD\n",
            "ROLL.or.Sheet.\n",
            "PROFESSION\n",
            "Notable\n",
            "Street.Address\n",
            "PLACEOFBIRTH\n",
            "RELIGION\n",
            "NOTE.these.only.apply.to.narrative.answers\n",
            "LIVING.W.MALE.FAMILY.\n",
            "LIVING.W.FEMALE.FAMILY.\n",
            "LIVING.W.MALE.NONFAMILY.\n",
            "LIVING.W.FEMALE.NONFAMILY.\n",
            "Cannot.Read\n",
            "Cannot.Write\n",
            "Sick\n",
            "Relation.to.Head.of.House\n",
            "Year.of.Immigration.to.Canada.if.an.Immigrant\n",
            "Date.of.Death\n",
            "Cause.of.Death\n",
            "Rank_Military\n",
            "Enlistment.Date\n",
            "Enlistment.Place\n",
            "Census.record.ID\n",
            "Location.ID\n",
            "Family.ID\n",
            "Birth.Month\n",
            "Birth.Day\n",
            "Employment.History\n",
            "Months.school\n",
            "Earnings\n",
            "English\n",
            "French\n",
            "Naturalization.Year\n",
            "Mother.Tongue\n",
            "Birthplace.Type\n",
            "Race\n",
            "Nationality\n",
            "Has.Annote\n",
            "Page\n",
            "Line\n",
            "Whitem\n",
            "Colouredm\n",
            "Colouredf\n",
            "Totalm\n",
            "Totalf\n",
            "Childrenm\n",
            "Childrenf\n",
            "Schoolm\n",
            "Schoolf\n",
            "Notes.Other.Information\n",
            "Last.Name.MATCH\n",
            "First.Name.Match\n",
            "Census.Year.Match\n",
            "Total.of.Matches\n",
            "Father.s.Name\n",
            "Mother.s.Name\n",
            "Spouse\n",
            "City\n",
            "MiddleName\n",
            "Residence.Place\n",
            "Death.Place\n",
            "Family.Number\n",
            "Attended.School\n",
            "House.Number\n",
            "Father.s.Birth.Place\n",
            "Mother.s.Birth.Place\n",
            "Immigration.Year\n",
            "Able.to.read\n",
            "Able.to.Write\n",
            "REGIMENT\n",
            "ORDER.NUMBER\n",
            "Regt.\n",
            "Application\n",
            "Full.Name\n",
            "Co.\n",
            "Height\n",
            "Complex.\n",
            "Father.of.Foreign.Birth\n",
            "Mother.of.Foreign.Birth\n",
            "Township\n",
            "Sheet.Number\n",
            "Noonan.Page.Number\n",
            "Employment\n",
            "Whitef\n",
            "full_name\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tCdQPGpcejB"
      },
      "source": [
        "# rename columns\n",
        "df = df.rename(columns = {# Personal Information\n",
        "                                       'Last.Name': 'last_name',\n",
        "                                       'First.Name': 'first_name', \n",
        "                                       # Places or Geography\n",
        "                                       'State.Province': 'state_or_province', \n",
        "                                       'County': 'county', \n",
        "                                       'Place': 'place', \n",
        "                                       'WARD': 'ward', \n",
        "                                       'Street.Address': 'street', \n",
        "                                       'PLACEOFBIRTH': 'place_of_birth',\n",
        "                                       'ROLL.or.Sheet.': 'roll_or_sheet',\n",
        "                                       # Years\n",
        "                                       'Census.Year': 'census_year', \n",
        "                                       'CalculatedBirthYear': 'calculated_birth_year', \n",
        "                                       # Personal information\n",
        "                                       'Sex': 'sex', \n",
        "                                       'Color..Race.or.Ethnicity': 'race',\n",
        "                                       'MARITAL': 'marital_status',\n",
        "                                       'PROFESSION': 'profession',\n",
        "                                       'Notable': 'notable',\n",
        "                                       'RELIGION': 'religion',\n",
        "                          'Joint.ID.for.Matched.Records': 'Joint ID for Matched Records'\n",
        "                          })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBXRHg1ectSB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c511235-ee9b-4630-aa3f-6e5f309fb99b"
      },
      "source": [
        "# master info\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 59519 entries, 0 to 59518\n",
            "Columns: 104 entries, unique_id to Whitef\n",
            "dtypes: float64(43), int64(1), object(60)\n",
            "memory usage: 47.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rcBom4ZfA5-"
      },
      "source": [
        "# chosen columns\n",
        "chosen_columns = ['last_name', \n",
        "                  'first_name',\n",
        "                  'state_or_province',\n",
        "                  'county',\n",
        "                  'place',\n",
        "                  'ward',\n",
        "                  'street',\n",
        "                  'place_of_birth',\n",
        "                  'roll_or_sheet',\n",
        "                  'lat',\n",
        "                  'long',\n",
        "                  'census_year',\n",
        "                  'calculated_birth_year',\n",
        "                  'sex',\n",
        "                  'race',\n",
        "                  'marital_status',\n",
        "                  'profession',\n",
        "                  'religion',\n",
        "                  'unique_id',\n",
        "                  'phonetic_name']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x668qHgkkqPy"
      },
      "source": [
        "# 2. Standardization/normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYR9PsV3lBSA"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uagDk14nkbi9"
      },
      "source": [
        "#name, phonetic\n",
        "column_to_parse = ['last_name', 'first_name']\n",
        "\n",
        "for c in column_to_parse:\n",
        "  df[c] = df.apply(lambda row: str(row[c]).lower(), axis = 1)\n",
        "\n",
        "df[\"phonetic_name\"] = phonetic(df['last_name'], 'soundex')+phonetic(df['first_name'], 'soundex')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOGdYNUZd9z8"
      },
      "source": [
        "# race\n",
        "def transform_race(row):    \n",
        "    \n",
        "    if pd.notnull(row['race']):\n",
        "        row['race'] = row['race'].lower()\n",
        "        row['race'] = row['race'].replace('\\xa0', '')\n",
        "        row['race'] = row['race'].replace('“', '')\n",
        "        row['race'] = row['race'].replace('”', '')\n",
        "    \n",
        "    race_dict = {'mulatto(blackandwhite)': 'MIXED',\n",
        "                 'm(wonancestry.com)': 'MIXED',\n",
        "                 'mulatto': 'MIXED',\n",
        "                 'mullato': 'MIXED',\n",
        "                 'm': 'MIXED',\n",
        "                 'm(winancestry.com)': 'MIXED',\n",
        "                 'black': 'BLACK',\n",
        "                 'b': 'BLACK',\n",
        "                 'blk': 'BLACK',\n",
        "                 'brown': 'BLACK',\n",
        "                 'african': 'BLACK',\n",
        "                 'dark': 'BLACK',\n",
        "                 'drk': 'BLACK',\n",
        "                 'african (black)': 'BLACK',\n",
        "                 'negro': 'BLACK',\n",
        "                 'blacj': 'BLACK', \n",
        "                 'bkj': 'BLACK', \n",
        "                 'light': 'WHITE',\n",
        "                 'white': 'WHITE',\n",
        "                 'w': 'WHITE',\n",
        "                 '[w]': 'WHITE',\n",
        "                 'white': 'WHITE',\n",
        "                 'seems to be white': 'WHITE',\n",
        "                 'white in black household': 'WHITE',\n",
        "                 'white but passing': 'WHITE',\n",
        "                 'ancestrysaysw': 'WHITE',\n",
        "                 'swarthy': 'BLACK',\n",
        "                 'd. brown': 'BLACK',\n",
        "                 'col.d': 'BLACK',\n",
        "                 'col\\'d': 'BLACK',\n",
        "                 }\n",
        "    if row['race'] in race_dict.keys():\n",
        "      return race_dict[row['race']]\n",
        "    elif pd.notnull(row['race']):\n",
        "      return 'OTHERS'\n",
        "    else:\n",
        "     return row['race']\n",
        "\n",
        "df['race'] = df.apply(lambda row: transform_race(row), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iJv3gFfeJ35",
        "outputId": "3ac3a2fc-b880-4793-d0bc-1c3fd0198020"
      },
      "source": [
        "df['state_or_province'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan, 'New York', 'Massachusetts', 'Michigan', 'Pennsylvania',\n",
              "       'Missouri', 'Maine', 'Ohio', 'Illinois', 'Rhode Island',\n",
              "       'Virginia', 'Wisconsin', 'Canada West', 'Ontario', 'Connecticut',\n",
              "       'California', 'New Jersey', 'Minnesota', 'Delaware', 'Maryland',\n",
              "       'Indiana', 'Texas', 'Washington DC', 'Iowa', 'Kansas', 'Vermont',\n",
              "       'Oregon', 'Louisiana', 'British Columbia', 'Mississippi',\n",
              "       'Oklahoma', 'Nebraska', 'Florida', 'Kentucky', 'Colorado',\n",
              "       'Washington', 'Arkansas', 'West Virginia', 'NB', 'Tennessee',\n",
              "       'South Carolina', 'Montana', 'Alabama', 'Alaska', 'Virgin Islands',\n",
              "       'Georgia', 'North Carolina', 'New Mexico', 'MIL: Usnavy',\n",
              "       'New Hampshire', 'Puerto Rico', 'North Dakota', 'Arizona', 'PANA',\n",
              "       'South Dakota', 'Wyoming', 'Idaho', 'Nevada', 'Hawaii',\n",
              "       'MIL: Philippines', 'MIL: Maryland', 'MIL: Massachusetts', 'Utah',\n",
              "       'Massachussetts', 'MIL: Southcarolina', 'MIL: Cuba', 'ITER',\n",
              "       'District of Columbia', 'Canada', 'NY', 'WA', 'IA', 'ME',\n",
              "       'New Brunswick', 'MI', 'Ontario ', 'VA', 'Nova Scotia', 'CO', 'IL',\n",
              "       'MA'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjHwLJZkqqKU"
      },
      "source": [
        "# locations (nameparser, fuzzy matching)\n",
        "def transform_state(row):    \n",
        "    \"\"\"\n",
        "    This function uses a dictionary\n",
        "    to covert historical or non-abbreviated states or provinces\n",
        "    into abbreviated form. \n",
        "    An important notice is that Canada West will all be converted into ON (Ontario).\n",
        "    Unknown values: PANA, ITER, MIL.\n",
        "    \"\"\"\n",
        "    state_dict = {\n",
        "                  'CO': 'Colorado',\n",
        "                  'MA': 'Massachussetts',\n",
        "                  'VA': 'Virginia',\n",
        "                  'IL': 'Illinois',\n",
        "                  'ME': 'Maine',\n",
        "                  'NY': 'New York',\n",
        "                  'MI': 'Michigan',\n",
        "                  'WA': 'Washington',\n",
        "                  'IA': 'Iowa',\n",
        "                  }\n",
        "    \n",
        "    if row['state_or_province'] in state_dict.keys():\n",
        "        return state_dict[row['state_or_province']]\n",
        "    else:\n",
        "        return row['state_or_province']\n",
        "\n",
        "df['state_or_province'] = df.apply(lambda row: transform_state(row), axis = 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C50vqqtEC4-5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOdd9aLlqp5i"
      },
      "source": [
        "# dates\n",
        "import datetime\n",
        "def prc_year(row, year_col):\n",
        "    \"\"\"\n",
        "    Processing birth year.\n",
        "    If birth year is not a number, not in a date format, or is noncompliant,\n",
        "    it will be converted to NaN.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Helper functions\n",
        "    def is_number(num):\n",
        "        try:\n",
        "            float(num)\n",
        "            return True\n",
        "        except ValueError:\n",
        "            return False\n",
        "    if (type(row[year_col]) is datetime.datetime):\n",
        "        row[year_col] = row[year_col].strftime(\"%Y\")\n",
        "    non_compliant_values = ['-', 'F', '#VALUE!']\n",
        "    if row[year_col] in non_compliant_values or pd.isnull(row[year_col]):\n",
        "        return np.nan\n",
        "    elif is_number(row[year_col]):\n",
        "        return float(row[year_col])\n",
        "    elif re.findall('\\d{4}', row[year_col]):\n",
        "        return min([float(i) for i in re.findall('\\d{4}', row[year_col])])\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "df['calculated_birth_year'] = df.apply(lambda row: prc_year(row, 'calculated_birth_year'),\n",
        "                                       axis = 1)\n",
        "df['census_year'] = df.apply(lambda row: prc_year(row, 'census_year'),\n",
        "                             axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uLjRKamrDaF"
      },
      "source": [
        "# clean place of birth\n",
        "def transform_birthplace(row):    \n",
        "    \"\"\"\n",
        "    This function uses a dictionary\n",
        "    to covert places of birth to cleaner strings\n",
        "    \"\"\"\n",
        "    if pd.notnull(row['place_of_birth']):\n",
        "      row['place_of_birth'] = str(row['place_of_birth'])\n",
        "      row['place_of_birth'] = row['place_of_birth'].lower()\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace('\\xa0', '')\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace('“', '')\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace('”', '')\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace('(', '')\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace(')', '')\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace('[', '')\n",
        "      row['place_of_birth'] = row['place_of_birth'].replace(']', '')\n",
        " \n",
        "      return row['place_of_birth']\n",
        "\n",
        "df['place_of_birth'] = df.apply(lambda row: transform_birthplace(row), axis = 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3MM07P6w_FL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4b320c-4236-40aa-81d1-14a46de49573"
      },
      "source": [
        "df['place_of_birth'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['usa', 'canada', 'maine', 'cw', 'can', 'ohio', 'michigan',\n",
              "       'british columbia, canada', None, 'victoria bc', 'canadawest',\n",
              "       'north carolina', 'uc', 'u.c.', 'new brunswick', 'mo', 'u. canada',\n",
              "       'windsor', 'ontario', '24990', 'unitedkingdom,n.s.', 'kentucky',\n",
              "       'indianna', 'detroit', 'northcarolina', 'chatham', 'texas',\n",
              "       '44030', 'do meaning u canada upper canada', 'md', 'lc',\n",
              "       'pennsylvania', 'virginia', 'arkansas', 'canadaw', 'minnesota',\n",
              "       'indiana', 'kansas', '44010', 'mississippi', 'chathamcw',\n",
              "       'missouri', 'wisconsin', 'amherstburg', 'united states',\n",
              "       'new york', 'ireland', 'ny', '99999', 'us', 'u.s.', 'germany',\n",
              "       'o ontario', 'washington', 'nj', 'lisa', 'new mexico', 'tennessee',\n",
              "       'newyork', '21230', 'milwaukie', 'illinois', 'mexico', '21130',\n",
              "       'eng', 'pa', 'il', 'ky', 'w', 'domeaningindiana', 'maryland',\n",
              "       '43090', '24010', 'ma', 'mi', '21140', '31010', 'alaska', 'va',\n",
              "       'sandwich', 'sweden', 'nova scotia', 'toronto', 'philadelphia',\n",
              "       'chatham, cw', '44090', 'italy', 'ire', 'missiouri', '44043',\n",
              "       '41030', 'toronto, cw residence rochester, ny', 'halifax, ns',\n",
              "       'st john, nb', 'buxton, cw', 'toronto, cw', 'gardsborough, ns',\n",
              "       '1', 'canada east', 'hamilton, cw', 'nassau, nb', 'essex co., cw',\n",
              "       'montreal, ce', 'canada w.', 'stlouis',\n",
              "       'toronto, cw residence urbana, ohio', '42090', '22060',\n",
              "       'covington, kentucky, usa', 'hamilton. cw residence blanford, ma.',\n",
              "       'malden, cw', 'montreal, cw', 'little york, cw', 'london, cw',\n",
              "       'toronto, canada w.', 'gosfield, canada', 'london, ontario',\n",
              "       'iowa', 'othercaribbeanandn.s.', 'kingston, cw',\n",
              "       'kingston, canada west', '5', 'kent co, cw', '23990', '80000',\n",
              "       '21080', 'norwich twp, cw', 'canada west', 'harwich, cw',\n",
              "       'canada,', 'st johns, new brunswick', 'canada british canadian',\n",
              "       'st. johns, nb.', '55', 'upper canada', 'kent co., cw', 'arizona',\n",
              "       '44080', 'uc meaning upper canada', 'win',\n",
              "       'not in fold3 quick - check others', 'amherstburg, cw',\n",
              "       'quebec, ce', 'n.b. same residence', 'lellyport ?, canada',\n",
              "       'u. states', '44020', '32040', '21050', 'kerrigan,, canada',\n",
              "       'guisbury n. scotia', 'vicksburg', 'mailstone, canada',\n",
              "       'montreal, ce residence, greenfield, ma.', 'ont ontario', '42010',\n",
              "       'districtcolumbia', 'st. catherines, cw', 'woodstock, cw',\n",
              "       'lowercanada', '43060', 'sco', 'deleware', 'windsor, cw',\n",
              "       'neworleans', 'st. johns, n. brunswick', 'st. andrews, nb',\n",
              "       'st. andrews, n brunswick', 'st. andres, n. brunswick', '41050',\n",
              "       '23040', 'memphis tn', '39990', 'pru', 'de', 'black', 'canada ba',\n",
              "       'louisiana', 'fingal co. canada', '15140', 'wi',\n",
              "       'canada residence boston', 'georgia', '34151', '51000', '21040',\n",
              "       'barbados', '15030',\n",
              "       'amherstburg, cw residence malden, cw, postwar ypsilanti, mich',\n",
              "       'alabama', 'richmond co county indiana us', '41080',\n",
              "       'massachusetts', 'nova scotia or not stated?', '21210', 'afr',\n",
              "       'st. johns new brunswick', '22000',\n",
              "       'virginia or michigan or canada', '41020', '21100', 'srcathermes',\n",
              "       'st. stephens, new brunswick', '43120', 'chatham, canada',\n",
              "       'british columbia', '-', '49999', '21150', 'ontario, canada',\n",
              "       'southcarolina', 'cincinnati',\n",
              "       'tksortbylat-long,orlastnamefirstnamebirththenlatlongor..?',\n",
              "       'england', 'sandwich, cw', 'newjersey', 'north caroline',\n",
              "       'u states', '42040', 'canada, english',\n",
              "       'pennsylvania, united states', 'states united states', 'al',\n",
              "       'vermont', 'guelph, canada', 'sc', 'east indies', 'delaware',\n",
              "       'westindies', 'richmond, ind. indiana', '19999', '23010', '51010',\n",
              "       'prince edward island', 'spain', 'nsc', 'stlouism',\n",
              "       'canada british province', 'connecticut', 'tennesse',\n",
              "       'west virginia', 'colorado', 'ga', 'district columbia',\n",
              "       'windsor, canada', 'st croix', 'sam',\n",
              "       'canada or virginia or michigan', 'jamaica', '21270', 'hai',\n",
              "       'canada english', '52010', 'maryland, u.s.', 'stcathermes',\n",
              "       '15070', 'u s', 'kentucky, u.s.', 'u.s.a.', 'blank', 'west indies',\n",
              "       'toronto, canada', 'indiana, u.s.', 'st helena',\n",
              "       'tennessee, united states', 'done', '102', 'domeaningmichigan',\n",
              "       'pei', '. canada', 'montrreal, canada', '26', '3',\n",
              "       'not in fold3 - check other', 'canada same residence', '20',\n",
              "       'benjamin f. talbot of seaforth, canada west was one such recruit. he joined the 5th usct as william thurman and gave his nationality as american although he returned to canada west as soon as he was mustered out. william thurman, civil war pension file, rg 94, national archives.',\n",
              "       '18', '31', '24', '25', '38', '23', 'niagara, cw',\n",
              "       'niagara, canada', 'canadian', 'victoria bc canada',\n",
              "       'chatham ontario canada', 'washington dc', 'new bedsoto conn',\n",
              "       'chatham ont, canada', 'chatham ont canada', 'scotland',\n",
              "       'cwtoronto', 'cw-wellington', 'ns-halifax', 'nb-frederickton',\n",
              "       'cw-toronto', 'cw-kingston', 'nb-st johns', 'ce-montreal',\n",
              "       'cw-malden', 'cw-little york', 'cw-hamilton', 'ns-elyport',\n",
              "       'ns-middleport', 'cw-sandwich', 'cw-buxton', 'cw-kent co',\n",
              "       'nb-st stepehens', 'cw-chatham', 'cw-blarck rock', 'cw-camden',\n",
              "       'ce-st estache', 'ns-guysborough', 'cw-prescott', 'cw-london',\n",
              "       'cwfinigal', 'nbst john', 'cemontreal', 'cwhamilton', 'nshalifax',\n",
              "       'nova scotia-halifax', 'cwwindsor', 'e', 'rc', 'cwchatham',\n",
              "       'nbst andrews', 'cw-stcatherines', 'cw-gray co', 'cw-woodstock',\n",
              "       'cw-windsor', 'nb-stjohn', 'i', 'cw-st catherines', 'cw-mailstown',\n",
              "       'cw-sarnia', 'cw-oxford co', 'cw-fort erie', 'ns-lockhartville',\n",
              "       'ns-lollyport', 'cwlondon', 'cwharwich', 'cwwoodstock', 'nbnassau',\n",
              "       'nb-grafton', 's', 'cw hampton', 'cwralleigh', 'boston',\n",
              "       'cw chatham', 'cwessex co', 'nbhillsborough', 'newfoundland',\n",
              "       'nscape breton', 'cwkingston', 'ce-st johns', 'v',\n",
              "       'ns-isaacs harbor', 'cw-plymouth', 'nb st johns', 'ie',\n",
              "       'cw-hampton', 'ns-annapolis', 'cwmalden', 'cwbuxton', 'cwgosfield',\n",
              "       'ns-yarmouth', 'cw-walden', 'cw-amhurstburg', 'ce',\n",
              "       '1.ââââ marks jerry unit 1st usct infantry home chatham canada west aae 18 other info farmer reduced to the ranks for drunkenness and insubordination',\n",
              "       '2.ââââ peaks james unit 1st usct infantry home st. catherines canada west aae 23 other info cook sentenced to hard labour by a general court martial',\n",
              "       '3.ââââ simmons john unit 1st usct infantry home canada aae 18 mustered out dld late 1865 other info farmer',\n",
              "       '4.ââââ st. dana james unit 1st usct infantry home canada west aae 27 other info farmer died in hospital at fort hatteras nc tldd dih 10 july 1865 fort hatteras nc cemetey new berne national nc plot 123 grave 14',\n",
              "       '5.ââââ thompson william unit 1st usct infantry home canada aae 35 mustered out dld late 1865 other info farmer',\n",
              "       'st. johns, nb', ' toronto, cw', 'toronto, canada west',\n",
              "       'st johns, nb', 'st. johns nb', 'n. brunswick', 'niagara,canada',\n",
              "       'â€œcanadianâ€\\x9d',\n",
              "       ' benjamin f. talbot of seaforth, canada west was one such recruit.  he joined the 5th usct as william thurman and gave his nationality as american although he returned to canada west as soon as he was mustered out.  â€œwilliam thurman,â€\\x9d civil war pension file, rg 94, national archives.',\n",
              "       'canada â€œbritish canadianâ€\\x9d',\n",
              "       'canada â€œbritish provinceâ€\\x9d',\n",
              "       'canada, â€œbritish provinceâ€\\x9d', 'â€œnew londonâ€\\x9d, cw',\n",
              "       'st. john, nb', 'kingston', 'â€œkerrigan,â€\\x9d, canada',\n",
              "       'middleport, canada', 'â€œlellyportâ€\\x9d ?,  canada',\n",
              "       'st catherines, cw', 'â€œkanastaâ€\\x9d. canada',\n",
              "       'â€œlittle yorkâ€\\x9d, cw', 'owen sound, cw', 'â€œcanada baâ€\\x9d',\n",
              "       'richmond, cw', 'st. stephens,  new brunswick',\n",
              "       'st. johns  new brunswick', 'port perrott canada', 'fort erie, cw',\n",
              "       'st. catherine, cw', 'galt, cw', 'georgetown, cw',\n",
              "       'st catherine, cw', 'brantford, cw', 'halifax, ns same residence',\n",
              "       'nova scotia ', 'yarmouth, ns same residence',\n",
              "       'hamilton, cw residence boston, postwar salem, ma',\n",
              "       'canada same residence, postwar hartford, conn.',\n",
              "       'st. john, nb same residence', 'black rock, canada', 'winsor, cw',\n",
              "       'yarmouth, ns', 'gray co., cw', 'ns', 'montrã©al, ce',\n",
              "       'wellington, cw', 'canada crossed out, \"kentucky\" added',\n",
              "       'st. john', 'thinle, ce', 'rawleigh, canada', 'new hampshire',\n",
              "       'nb', 'maine, usa', 'virginia, usa',\n",
              "       'houlton, aroostook, maine, usa', 'covington, ky, usa', '?',\n",
              "       'can ', 'dc', 'jam', 'chatham canada w', 'south carolina',\n",
              "       'st john, new brunswick', 'kennebunk, maine'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEhnJSfFphNv"
      },
      "source": [
        "# fill empty columns\n",
        "columns_to_impute_with_unknown = ['state_or_province',\n",
        "                                  'county',\n",
        "                                  'place',\n",
        "                                  'ward',\n",
        "                                  'street',\n",
        "                                  'place_of_birth',\n",
        "                                  'sex',\n",
        "                                  'race',\n",
        "                                  'marital_status',\n",
        "                                  'profession',\n",
        "                                  'religion']\n",
        "\n",
        "for i in columns_to_impute_with_unknown:\n",
        "    df[i] = df[i].fillna('unknown')\n",
        "\n",
        "columns_to_impute_with_zero = ['roll_or_sheet',\n",
        "                               'lat',\n",
        "                               'long',]\n",
        "\n",
        "for i in columns_to_impute_with_zero:\n",
        "    df[i] = df[i].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqYl-saGLM3G"
      },
      "source": [
        "# dealing with the 'unknowns'\n",
        "chrs = 'abcdefghijklmnopqrstuvwxyz0123456789 '\n",
        "\n",
        "location_columns = ['county', 'place', 'place_of_birth', 'state_or_province']\n",
        "\n",
        "count = 0\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    if all([row[i] == 'unknown' for i in location_columns]):\n",
        "      continue\n",
        "    else:\n",
        "      for l in location_columns:\n",
        "        c = \"\".join(np.random.choice(list(chrs), 20))\n",
        "        row[l] = c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z0TszwdksXQ"
      },
      "source": [
        "# 3. Linkage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PPMBNc3j84w"
      },
      "source": [
        "# match all\n",
        "df1 = df[chosen_columns]\n",
        "df2 = df[chosen_columns]\n",
        "\n",
        "# block on phoenetic full name\n",
        "indexer = rl.Index()\n",
        "indexer.add(Block('phonetic_name', 'phonetic_name'))\n",
        "record_links = indexer.index(df1, df2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ83sKYkRPn2",
        "outputId": "3ff4d0f4-f0fb-4246-eda2-f3db804223ac"
      },
      "source": [
        "df[pd.isnull(df['Joint ID for Matched Records'])].shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52319, 105)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ueo2GPEpcts"
      },
      "source": [
        "# unmatched VS matched\n",
        "# df_withmatch = df[pd.notnull(df['Joint ID for Matched Records'])]\n",
        "# df_nomatch = df[pd.isnull(df['Joint ID for Matched Records'])]\n",
        "# chosen_columns.append(\"phonetic_name\")\n",
        "\n",
        "# df_withmatch = df_withmatch[chosen_columns]\n",
        "# df_nomatch = df_nomatch[chosen_columns]\n",
        "\n",
        "# indexer = rl.Index()\n",
        "# indexer.add(Block('phonetic_name', 'phonetic_name'))\n",
        "# record_links = indexer.index(df_withmatch, df_nomatch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrpp4CXSj7bZ",
        "outputId": "fba2b3a7-799e-484c-ffa3-d843aa9fc960"
      },
      "source": [
        "comparer = rl.Compare()\n",
        "comparer.string('first_name', 'first_name', method = 'jarowinkler', threshold = 0.85, label = 'first_name')\n",
        "comparer.string('last_name', 'last_name', method = 'jarowinkler', threshold = 0.85, label = 'last_name')\n",
        "comparer.string('state_or_province', 'state_or_province', method = 'jarowinkler', threshold = 0.5, \n",
        "                label = 'state_or_province')\n",
        "comparer.string('county', 'county', method = 'jarowinkler', threshold = 0.35, label = 'county')\n",
        "comparer.string('place', 'place', method = 'jarowinkler', threshold = 0.35, label = 'place')\n",
        "comparer.string('place_of_birth', 'place_of_birth', method = 'jarowinkler', threshold = 0.6, label = 'place_of_birth')\n",
        "comparer.string('race', 'race', method = 'jarowinkler', threshold = 0.7, label = 'race')\n",
        "comparer.string('sex', 'sex', method = 'jarowinkler', threshold = 0.7, label = 'sex')\n",
        "\n",
        "comparer.numeric('calculated_birth_year', 'calculated_birth_year', \n",
        "                 method = 'gauss', \n",
        "                 offset = 1, \n",
        "                 scale = 1, \n",
        "                 label = 'calculated_birth_year')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Compare>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIkvZhHJj8ME"
      },
      "source": [
        "Output Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJRvgeQKq3nH"
      },
      "source": [
        "import sys\n",
        "sys.setrecursionlimit(1000000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIrPaUJblpTj"
      },
      "source": [
        "compare_vectors_rl = comparer.compute(record_links, df1, df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-RU3e_q6Rr3"
      },
      "source": [
        "result_rl = compare_vectors_rl[((compare_vectors_rl['first_name'] == 1.0) & \n",
        "                                (compare_vectors_rl['last_name'] == 1.0)) &\n",
        "                               ((compare_vectors_rl['state_or_province'] == 1.0) |\n",
        "                                (compare_vectors_rl['county'] == 1.0) |\n",
        "                                (compare_vectors_rl['place'] == 1.0) |\n",
        "                                (compare_vectors_rl['place_of_birth'] == 1.0)) &\n",
        "                               (compare_vectors_rl['sex'] == 1.0) &\n",
        "                               (compare_vectors_rl['race'] == 1.0) & \n",
        "                               ((compare_vectors_rl['calculated_birth_year'] > compare_vectors_rl['calculated_birth_year'].mean())\n",
        "                               | (compare_vectors_rl['calculated_birth_year'] == np.nan))].\\\n",
        "                               reset_index()\n",
        "\n",
        "result_rl = result_rl[result_rl['level_0'] != result_rl['level_1']].reset_index()\n",
        "result_rl.drop('index', axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEfXul4Upc1U"
      },
      "source": [
        "def create_indexid(row):\n",
        "    return \"\".join(sorted([str(int(i)) for i in [row['level_0'], row['level_1']]]))\n",
        "\n",
        "result_rl['indexid'] = result_rl.apply(lambda row: create_indexid(row), axis = 1)\n",
        "result_rl = result_rl.drop_duplicates('indexid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXTCj9CfRdSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cdcb13a-1b64-40ee-f09a-53024aff3813"
      },
      "source": [
        "# parse unsures into a dictionary\n",
        "from collections import defaultdict\n",
        "already_seen_pairs = defaultdict(set)\n",
        "\n",
        "for id, list_unsures in list(zip(df.unique_id, df.unsure_ids)):\n",
        "  if list_unsures[1:-1] != \"\":\n",
        "    already_seen_pairs[id] = set(list_unsures[1:-1].split(\", \"))\n",
        "  if id == 41810:\n",
        "    print(list_unsures[1:-1])\n",
        "\n",
        "for id, list_nos in list(zip(df.unique_id, df.no_ids)):\n",
        "  if list_nos[1:-1] != \"\":\n",
        "    already_seen_pairs[id] = set(list_nos[1:-1].split(\", \"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42190, 41360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmFaIuG-phbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2010f049-5843-4311-c1d3-91a081ff2798"
      },
      "source": [
        "df_result_rl.reset_index(inplace = True)\n",
        "df_result_rl = df_result_rl.drop('index', axis = 1)\n",
        "df_result_rl.head()\n",
        "df_result_rl.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3014, 105)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAnER6MypjSX"
      },
      "source": [
        "num_list = []\n",
        "for i in range(int(df_result_rl.shape[0]/2)):\n",
        "    num_list.append(i)\n",
        "    num_list.append(i)\n",
        "df_result_rl['dup_pair'] = pd.Series(num_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM6YkhVxplTj"
      },
      "source": [
        "col_order = ['dup_pair']\n",
        "col_order.extend(df.columns.tolist())\n",
        "df_result_rl = df_result_rl[col_order]\n",
        "output = root + \"/newmatches-3-17-21.xlsx\"\n",
        "df_result_rl.to_excel(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN-zNDY8oI1w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "714f022c-3f08-43f5-b5e4-73dc920f28a6"
      },
      "source": [
        "df_result_rl.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dup_pair</th>\n",
              "      <th>unique_id</th>\n",
              "      <th>source</th>\n",
              "      <th>census_year</th>\n",
              "      <th>state_or_province</th>\n",
              "      <th>county</th>\n",
              "      <th>place</th>\n",
              "      <th>unsure_ids</th>\n",
              "      <th>no_ids</th>\n",
              "      <th>Household.Joint.ID</th>\n",
              "      <th>Joint ID for Matched Records</th>\n",
              "      <th>last_name</th>\n",
              "      <th>first_name</th>\n",
              "      <th>calculated_birth_year</th>\n",
              "      <th>Age</th>\n",
              "      <th>sex</th>\n",
              "      <th>race</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>address</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>ward</th>\n",
              "      <th>roll_or_sheet</th>\n",
              "      <th>profession</th>\n",
              "      <th>notable</th>\n",
              "      <th>street</th>\n",
              "      <th>place_of_birth</th>\n",
              "      <th>religion</th>\n",
              "      <th>NOTE.these.only.apply.to.narrative.answers</th>\n",
              "      <th>LIVING.W.MALE.FAMILY.</th>\n",
              "      <th>LIVING.W.FEMALE.FAMILY.</th>\n",
              "      <th>LIVING.W.MALE.NONFAMILY.</th>\n",
              "      <th>LIVING.W.FEMALE.NONFAMILY.</th>\n",
              "      <th>Cannot.Read</th>\n",
              "      <th>Cannot.Write</th>\n",
              "      <th>Sick</th>\n",
              "      <th>Relation.to.Head.of.House</th>\n",
              "      <th>Year.of.Immigration.to.Canada.if.an.Immigrant</th>\n",
              "      <th>Date.of.Death</th>\n",
              "      <th>Cause.of.Death</th>\n",
              "      <th>...</th>\n",
              "      <th>Childrenm</th>\n",
              "      <th>Childrenf</th>\n",
              "      <th>Schoolm</th>\n",
              "      <th>Schoolf</th>\n",
              "      <th>Notes.Other.Information</th>\n",
              "      <th>Last.Name.MATCH</th>\n",
              "      <th>First.Name.Match</th>\n",
              "      <th>Census.Year.Match</th>\n",
              "      <th>Total.of.Matches</th>\n",
              "      <th>Father.s.Name</th>\n",
              "      <th>Mother.s.Name</th>\n",
              "      <th>Spouse</th>\n",
              "      <th>City</th>\n",
              "      <th>MiddleName</th>\n",
              "      <th>Residence.Place</th>\n",
              "      <th>Death.Place</th>\n",
              "      <th>Family.Number</th>\n",
              "      <th>Attended.School</th>\n",
              "      <th>House.Number</th>\n",
              "      <th>Father.s.Birth.Place</th>\n",
              "      <th>Mother.s.Birth.Place</th>\n",
              "      <th>Immigration.Year</th>\n",
              "      <th>Able.to.read</th>\n",
              "      <th>Able.to.Write</th>\n",
              "      <th>REGIMENT</th>\n",
              "      <th>ORDER.NUMBER</th>\n",
              "      <th>Regt.</th>\n",
              "      <th>Application</th>\n",
              "      <th>Full.Name</th>\n",
              "      <th>Co.</th>\n",
              "      <th>Height</th>\n",
              "      <th>Complex.</th>\n",
              "      <th>Father.of.Foreign.Birth</th>\n",
              "      <th>Mother.of.Foreign.Birth</th>\n",
              "      <th>Township</th>\n",
              "      <th>Sheet.Number</th>\n",
              "      <th>Noonan.Page.Number</th>\n",
              "      <th>Employment</th>\n",
              "      <th>Whitef</th>\n",
              "      <th>phonetic_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>48688.0</td>\n",
              "      <td>1880 IPUMS 100% sample</td>\n",
              "      <td>1880.0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>unknown</td>\n",
              "      <td>unknown</td>\n",
              "      <td>[49221, 49093]</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>williams</td>\n",
              "      <td>george</td>\n",
              "      <td>1880.0</td>\n",
              "      <td>0</td>\n",
              "      <td>M</td>\n",
              "      <td>BLACK</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ATHOME</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>usa</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>99</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>|||</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W452G620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>49094.0</td>\n",
              "      <td>13040</td>\n",
              "      <td>1910.0</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>Will</td>\n",
              "      <td>Joliet</td>\n",
              "      <td>[1756, 49093, 49221, 48632, 49093]</td>\n",
              "      <td>[48632]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>williams</td>\n",
              "      <td>george</td>\n",
              "      <td>1878.0</td>\n",
              "      <td>32</td>\n",
              "      <td>M</td>\n",
              "      <td>BLACK</td>\n",
              "      <td>41.419406</td>\n",
              "      <td>-87.999475</td>\n",
              "      <td>JOLIET,WILL,IL</td>\n",
              "      <td>unknown</td>\n",
              "      <td>unknown</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>YCHECK</td>\n",
              "      <td></td>\n",
              "      <td>unknown</td>\n",
              "      <td>unknown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>|||</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W452G620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>49093.0</td>\n",
              "      <td>4475</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>Missouri</td>\n",
              "      <td>Jackson</td>\n",
              "      <td>Kansascity</td>\n",
              "      <td>[1756, 49094, 49221, 49094, 48688]</td>\n",
              "      <td>[49219]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>williams</td>\n",
              "      <td>george</td>\n",
              "      <td>1878.0</td>\n",
              "      <td>22</td>\n",
              "      <td>M</td>\n",
              "      <td>BLACK</td>\n",
              "      <td>39.035409</td>\n",
              "      <td>-94.358275</td>\n",
              "      <td>KANSASCITY,JACKSON,MO</td>\n",
              "      <td>unknown</td>\n",
              "      <td>unknown</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>YCHECK</td>\n",
              "      <td></td>\n",
              "      <td>unknown</td>\n",
              "      <td>unknown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>|||</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W452G620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>49094.0</td>\n",
              "      <td>13040</td>\n",
              "      <td>1910.0</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>Will</td>\n",
              "      <td>Joliet</td>\n",
              "      <td>[1756, 49093, 49221, 48632, 49093]</td>\n",
              "      <td>[48632]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>williams</td>\n",
              "      <td>george</td>\n",
              "      <td>1878.0</td>\n",
              "      <td>32</td>\n",
              "      <td>M</td>\n",
              "      <td>BLACK</td>\n",
              "      <td>41.419406</td>\n",
              "      <td>-87.999475</td>\n",
              "      <td>JOLIET,WILL,IL</td>\n",
              "      <td>unknown</td>\n",
              "      <td>unknown</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>YCHECK</td>\n",
              "      <td></td>\n",
              "      <td>unknown</td>\n",
              "      <td>unknown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>|||</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W452G620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>3468.0</td>\n",
              "      <td>1900 IPUMS 5% sample</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>unknown</td>\n",
              "      <td>unknown</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>artist</td>\n",
              "      <td>elige</td>\n",
              "      <td>1857.0</td>\n",
              "      <td>43</td>\n",
              "      <td>M</td>\n",
              "      <td>BLACK</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Gardener</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>canada</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>|||</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A632E420</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 106 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   dup_pair  unique_id                  source  ...  Employment Whitef phonetic_name\n",
              "0         0    48688.0  1880 IPUMS 100% sample  ...         NaN    NaN      W452G620\n",
              "1         0    49094.0                   13040  ...         NaN    NaN      W452G620\n",
              "2         1    49093.0                    4475  ...         NaN    NaN      W452G620\n",
              "3         1    49094.0                   13040  ...         NaN    NaN      W452G620\n",
              "4         2     3468.0    1900 IPUMS 5% sample  ...         NaN    NaN      A632E420\n",
              "\n",
              "[5 rows x 106 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    }
  ]
}